{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAQvvX0tuEyprGafxqTk6/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Benchmarking of various models for spam detection."],"metadata":{"id":"GG49EBdUOom-"}},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgY5FcFFIgG_","executionInfo":{"status":"ok","timestamp":1702589207670,"user_tz":300,"elapsed":864,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}},"outputId":"2d70c173-6171-4117-ae97-ebfff7a4acac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/EECS_6448/Data\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/EECS_6448/Data"]},{"cell_type":"code","source":["\n","from __future__ import annotations\n","import os\n","import warnings\n","import pandas as pd\n","from typing import Callable, Tuple\n","\n","warnings.filterwarnings('ignore')\n","\n","# Data Preprocessing & NLP\n","import nltk\n","import unicodedata\n","import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","\n","# Download NLTK resources\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8ywFg6VIk62","executionInfo":{"status":"ok","timestamp":1702589207670,"user_tz":300,"elapsed":5,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}},"outputId":"1130c197-6207-4ad3-b13c-228ec33b3696"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["# Function to clean and preprocess text\n","def clean_text(text: str) -> str:\n","    STOPWORDS = set(stopwords.words('english'))\n","    TOK = nltk.tokenize.toktok.ToktokTokenizer()\n","    PORTER_STEMMER = nltk.PorterStemmer()\n","    WHITELIST = string.digits + string.whitespace + string.ascii_letters\n","\n","    # Replace accented chars with normal form\n","    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').strip()\n","\n","    # Remove double space\n","    while '  ' in text:\n","        text = text.replace('  ', ' ')\n","\n","    # Keep only A-Z, a-z, 0-9, space\n","    text = ''.join(c for c in text if c in WHITELIST)\n","\n","    tokens = [t.strip() for t in TOK.tokenize(text.lower())]\n","    tokens = [t for t in tokens if t not in STOPWORDS]\n","    text = ' '.join([PORTER_STEMMER.stem(word) for word in tokens])\n","\n","    return text"],"metadata":{"id":"Vfu7G7weIoPn","executionInfo":{"status":"ok","timestamp":1702589207671,"user_tz":300,"elapsed":3,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["# Function to load and preprocess data\n","def load_and_preprocess_data(file_path: str, target_column: str) -> pd.DataFrame:\n","    df = pd.read_csv(file_path, names=[\"App\", \"Source\", \"Author\", \"ReviewID\", \"Language\", \"Unnamed\", \"Star\", \"Date\", \"User\", \"Summary\", \"Review\", \"Category\"])\n","    df = df.drop(\"Unnamed\", axis=1)\n","    df['Review'] = df['Summary'] + ' ' + df['Review']\n","    df.fillna('nan', inplace=True)\n","    df['Review_proc'] = df['Review'].apply(clean_text)\n","    df = df.drop(\"Summary\", axis=1)\n","    df['Target'] = df[target_column].apply(lambda x: 0 if 's' in str(x) else 1)\n","    return df"],"metadata":{"id":"ZyRKAPHgIsjB","executionInfo":{"status":"ok","timestamp":1702589207671,"user_tz":300,"elapsed":2,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["# Function to balance the dataset\n","def balance_dataset(df: pd.DataFrame, target_column: str) -> pd.DataFrame:\n","    class_counts = df[target_column].value_counts()\n","    min_count = class_counts.min()\n","    df = pd.concat([df[df[target_column] == label].sample(min_count) for label in df[target_column].unique()])\n","    df = df.sample(frac=1).reset_index(drop=True)\n","    return df"],"metadata":{"id":"qO7QkYhPI1wm","executionInfo":{"status":"ok","timestamp":1702589207671,"user_tz":300,"elapsed":2,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["# Function to prepare data for modeling\n","def prepare_data_for_modeling(df: pd.DataFrame, target_column: str) -> Tuple:\n","    X = df['Review_proc']\n","    y = df['Target']\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    tfidf_vec = TfidfVectorizer(ngram_range=(1, 3), max_features=5000)\n","    tfidf_vec.fit(df['Review_proc'].to_numpy())\n","\n","    X_train = tfidf_vec.transform(X_train.to_numpy())\n","    y_train = y_train.to_numpy()\n","\n","    X_test = tfidf_vec.transform(X_test.to_numpy())\n","    y_test = y_test.to_numpy()\n","\n","    label_encoder = LabelEncoder()\n","    y_train = label_encoder.fit_transform(y_train)\n","    y_test = label_encoder.fit_transform(y_test)\n","\n","    return X_train, X_test, y_train, y_test"],"metadata":{"id":"pzdBOmCcI2dA","executionInfo":{"status":"ok","timestamp":1702589207779,"user_tz":300,"elapsed":110,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["# Function to train and evaluate a model\n","def train_and_evaluate_model(model: Callable, X_train, y_train, X_test, y_test) -> float:\n","    classifier = model()\n","    classifier.fit(X_train, y_train)\n","    y_pred = classifier.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    return accuracy"],"metadata":{"id":"_7TSh8UQI6Xj","executionInfo":{"status":"ok","timestamp":1702589207779,"user_tz":300,"elapsed":1,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["def test_multiple_models(file_path: str, category_column: str, target_column: str):\n","    df = load_and_preprocess_data(file_path, category_column)\n","    df = balance_dataset(df, target_column)\n","    X_train, X_test, y_train, y_test = prepare_data_for_modeling(df, target_column)\n","\n","    models = {\n","        \"RandomForest\": RandomForestClassifier,\n","        \"MultinomialNB\": MultinomialNB,\n","        \"SVM\": SVC,\n","        \"LogisticRegression\": LogisticRegression,\n","        \"KNeighbors\": KNeighborsClassifier,\n","        \"GradientBoosting\": GradientBoostingClassifier,\n","        \"AdaBoost\": AdaBoostClassifier,\n","        \"MLPClassifier\": MLPClassifier,\n","    }\n","\n","    for model_name, model_class in models.items():\n","        print(f\"Training {model_name}...\")\n","        classifier = model_class()\n","        classifier.fit(X_train, y_train)\n","\n","        print(\"Making predictions on the test set...\")\n","        y_pred = classifier.predict(X_test)\n","\n","        accuracy = accuracy_score(y_test, y_pred)\n","        print(f\"{model_name} - Accuracy: {accuracy:.4f}\")\n","        print(\"Classification Report:\")\n","        print(classification_report(y_test, y_pred))\n","\n","# Example usage\n","test_multiple_models('Data/spam.csv', 'Category', 'Target')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3DTsjnjI8fM","executionInfo":{"status":"ok","timestamp":1702589234086,"user_tz":300,"elapsed":26308,"user":{"displayName":"Faiz Ahmed","userId":"14775659622452611671"}},"outputId":"e8593fdf-88f5-4ceb-9083-bcbb52e4819e"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Training RandomForest...\n","Making predictions on the test set...\n","RandomForest - Accuracy: 0.7255\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.96      0.78        79\n","           1       0.92      0.47      0.62        74\n","\n","    accuracy                           0.73       153\n","   macro avg       0.79      0.72      0.70       153\n","weighted avg       0.79      0.73      0.71       153\n","\n","Training MultinomialNB...\n","Making predictions on the test set...\n","MultinomialNB - Accuracy: 0.7320\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.71      0.73        79\n","           1       0.71      0.76      0.73        74\n","\n","    accuracy                           0.73       153\n","   macro avg       0.73      0.73      0.73       153\n","weighted avg       0.73      0.73      0.73       153\n","\n","Training SVM...\n","Making predictions on the test set...\n","SVM - Accuracy: 0.6209\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.47      0.56        79\n","           1       0.58      0.78      0.67        74\n","\n","    accuracy                           0.62       153\n","   macro avg       0.64      0.63      0.61       153\n","weighted avg       0.64      0.62      0.61       153\n","\n","Training LogisticRegression...\n","Making predictions on the test set...\n","LogisticRegression - Accuracy: 0.7255\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.75      0.74        79\n","           1       0.72      0.70      0.71        74\n","\n","    accuracy                           0.73       153\n","   macro avg       0.73      0.72      0.72       153\n","weighted avg       0.73      0.73      0.73       153\n","\n","Training KNeighbors...\n","Making predictions on the test set...\n","KNeighbors - Accuracy: 0.5294\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.52      1.00      0.69        79\n","           1       1.00      0.03      0.05        74\n","\n","    accuracy                           0.53       153\n","   macro avg       0.76      0.51      0.37       153\n","weighted avg       0.75      0.53      0.38       153\n","\n","Training GradientBoosting...\n","Making predictions on the test set...\n","GradientBoosting - Accuracy: 0.7451\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.86      0.78        79\n","           1       0.81      0.62      0.70        74\n","\n","    accuracy                           0.75       153\n","   macro avg       0.76      0.74      0.74       153\n","weighted avg       0.76      0.75      0.74       153\n","\n","Training AdaBoost...\n","Making predictions on the test set...\n","AdaBoost - Accuracy: 0.7320\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.85      0.77        79\n","           1       0.79      0.61      0.69        74\n","\n","    accuracy                           0.73       153\n","   macro avg       0.74      0.73      0.73       153\n","weighted avg       0.74      0.73      0.73       153\n","\n","Training MLPClassifier...\n","Making predictions on the test set...\n","MLPClassifier - Accuracy: 0.7582\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.92      0.80        79\n","           1       0.88      0.58      0.70        74\n","\n","    accuracy                           0.76       153\n","   macro avg       0.79      0.75      0.75       153\n","weighted avg       0.79      0.76      0.75       153\n","\n"]}]}]}